{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters for domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the hyperparameters for generating a domain. The domain as assumed to be a simply non-hierarchical structure where all kc's are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "import copy\n",
    "from collections.abc import Iterable\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import minimize\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger(\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutor.domain import Domain\n",
    "from tutor.cogtutor_curriculum import CogTutorCurriculum\n",
    "from tutor.tutor import SimpleTutor\n",
    "from tutor.action import Attempt, HintRequest\n",
    "from learner.domain_tuner import DomainTuner\n",
    "\n",
    "from simulate.self_eff_simulation import SelfEffSimulation\n",
    "from log_db import mongo\n",
    "from log_db.curriculum_mapper import DB_Curriculum_Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to current project directory\n",
    "cwd = os.path.abspath(\".\")\n",
    "base_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "logger.debug(\"Base directory for the project:\\n%s\" % base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection to database\n",
    "data_out = \"sim-%s\" % str(uuid.uuid4())\n",
    "data_path = os.path.join(base_dir,\"test\", \"data\", data_out)\n",
    "logger.info(\"Writing simulation results to directory: %s\" % data_path)\n",
    "db_name = \"motivsim\"\n",
    "db_params  = mongo.get_db_params(db_name)\n",
    "logger.info(\"got db params: %s\" % str(db_params))\n",
    "db_util = mongo.Data_Utility(data_path, db_params)\n",
    "db = db_util.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Clearing database before starting new simulation\")\n",
    "db_util.clear_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory pass for Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Domain & Curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating empty domain\n",
    "domain = Domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Curriculum and domain together\n",
    "curric = CogTutorCurriculum(domain)\n",
    "curric.generate(num_units=1,\n",
    "               mean_sections=1,\n",
    "               stdev_sections=0,\n",
    "               mean_unit_kcs=5,\n",
    "               stdev_unit_kcs=1,\n",
    "               section_kcs_lambda=6,\n",
    "               mean_steps=4,\n",
    "               stdev_steps=1,\n",
    "               mean_prob_kcs=3,\n",
    "               stdev_prob_kcs=1,\n",
    "               num_practice=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert domain to db\n",
    "db.domains.insert_one(domain.to_dict())\n",
    "db.kcs.insert_many([kc.__dict__ for kc in domain.kcs])\n",
    "\n",
    "# Insert Curriculum to db\n",
    "curric_util = DB_Curriculum_Mapper(db_params)\n",
    "curric_util.write_to_db(curric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_students = 2\n",
    "students = [DomainTuner(domain) for i in range(num_students)]\n",
    "logger.info(\"Sample student:\\n%s\" % str(students[0]))\n",
    "logger.info(\"Inserting %i students to db\" % len(students))\n",
    "result = db.students.insert_many([stu.to_dict() for stu in students])\n",
    "logger.info(\"Db insert success: %s\" % result.acknowledged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stu in enumerate(students):\n",
    "    logger.info(\"Simulating student #%i\" % i)\n",
    "    sim = SelfEffSimulation(domain, curric, stu)\n",
    "    sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List size of all collections\n",
    "db_util.peak()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain & Cirriculum EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_counts = []\n",
    "prob_counts = []\n",
    "for j, unit in enumerate(curric.units):\n",
    "    logger.info(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "    logger.info(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "    logger.info(\"Unit #%i\" % j)\n",
    "    for i, section in enumerate(unit.sections):\n",
    "        logger.info(\"##########################################\")\n",
    "        logger.info(\"Section #%i: %s\" % (i, section._id))\n",
    "        logger.info(\"Number of kcs: %i\" % len(section.kcs))\n",
    "        kc_counts.append(len(section.kcs))\n",
    "        logger.info(\"Number of Problems: %i\" % len(section.problems))\n",
    "        prob_counts.append(len(section.problems))\n",
    "        step_counts = [len(prob.steps) for prob in section.problems]\n",
    "        \n",
    "        step_dist = {val: step_counts.count(val) for val in set(step_counts)}\n",
    "        logger.info(\"Distribution of steps across problems: %s\" % str(step_dist))\n",
    "    \n",
    "kc_dist = {val: kc_counts.count(val) for val in set(kc_counts)}\n",
    "prob_dist = {val: prob_counts.count(val) for val in set(prob_counts)}\n",
    "logger.info(\"------------------- Total Curric stats --------------------------\")\n",
    "logger.info(\"Distribution of kcs per section: %s\" % str(kc_dist))\n",
    "logger.info(\"Distribution of prob per section: %s\" % str(prob_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_kcs = [len(unit.kcs) for unit in curric.units]\n",
    "plt.hist(unit_kcs, bins=8)\n",
    "plt.title(\"Number of kcs in the unit\")\n",
    "plt.show()\n",
    "logger.info(\"Total number of kcs: %i\" % np.sum(unit_kcs))\n",
    "logger.info(pd.Series(unit_kcs).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_kcs = []\n",
    "for unit in curric.units:\n",
    "    section_kcs.extend([len(section.kcs) for section in unit.sections])\n",
    "plt.hist(section_kcs, bins=10)\n",
    "plt.title(\"Number of kcs in a section\")\n",
    "plt.show()\n",
    "logger.info(pd.Series(section_kcs).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### steps per problem EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_counts = []\n",
    "for unit in curric.units:\n",
    "    for section in unit.sections:\n",
    " #       logger.info(\"Section with %i kcs and %i problems\" % (len(section.kcs), len(section.problems)))\n",
    "        counts = pd.Series([len(prob.steps) for prob in section.problems]).value_counts()\n",
    "#        logger.info(\"Counts of steps per problems \\n%s\" % str(counts))\n",
    "        step_counts.append(counts)\n",
    "\n",
    "    \n",
    "prob_steps = pd.DataFrame(step_counts).sum(axis=0)\n",
    "logger.info(\"Distribution of steps per problems: \\n%s\" %  str(prob_steps))\n",
    "plt.bar(prob_steps.index, prob_steps)\n",
    "plt.title(\"Steps per problem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get learner transactions\n",
    "tx = pd.DataFrame(db.tutor_events.find({'type': \"Tutor Input\"}))\n",
    "logger.info(\"Learner Transactions: %s\" % str(tx.shape))\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add kc field that reduces list of kcs to 1 kc\n",
    "tx['kc'] = tx.apply(lambda x: x['kcs'][0]['_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Learner transaction stats\n",
    "\n",
    "# Total Transaction counts\n",
    "stu_stats = tx.groupby('stu_id').agg({'_id': 'count', \n",
    "                                      'duration': np.sum,\n",
    "                                     })\n",
    "stu_stats.rename(columns={'_id': \"Total Tx\",\n",
    "                          'duration': 'Total Time'}, \n",
    "                         inplace = True)\n",
    "stu_stats['Total Time(hours)'] = stu_stats['Total Time'].apply(lambda x: x / 3600)\n",
    "logger.info(\"Number of students: %i\" % stu_stats.shape[0])\n",
    "logger.info(stu_stats[\"Total Tx\"].describe())\n",
    "\n",
    "# Total of each outcome\n",
    "d = tx.groupby(['stu_id','outcome'])['_id'].count().reset_index().pivot(index='stu_id', columns='outcome', values='_id')\n",
    "\n",
    "# Prorporation of each outcome\n",
    "if len(d.columns) > 1:\n",
    "    d['Total'] = d.sum(axis=1)\n",
    "else:\n",
    "    d['Total'] = d.iloc[:,0]\n",
    "    \n",
    "for col in d.columns:\n",
    "    if col != 'Total':\n",
    "        d['Pct %s' % col] = d[col] / d['Total']\n",
    "stu_stats = pd.concat([stu_stats, d], axis=1)\n",
    "logger.info(stu_stats.shape)\n",
    "\n",
    "logger.info(stu_stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.subplot(121)\n",
    "plt.hist(stu_stats['Total Tx'], bins=10)\n",
    "plt.title(\"Total Tx\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(stu_stats['Total Time(hours)'], bins=10)\n",
    "plt.title(\"Total Time(hours)\")\n",
    "plt.show()\n",
    "\n",
    "num_pct = np.sum([\"Pct\" in col for col in stu_stats.columns])\n",
    "width = 4\n",
    "plt.figure(figsize=(width*num_pct + num_pct, 2))\n",
    "for i, col in enumerate([c for c in stu_stats.columns if \"Pct\" in c]):\n",
    "    plt.subplot(1,num_pct,i+1)\n",
    "    plt.hist(stu_stats[col], bins=10)\n",
    "    plt.title(col)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(tx['duration'],bins=50)\n",
    "plt.title(\"Tx duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_stats = tx.groupby(['stu_id', 'unit_id', 'section_id', 'prob_id', 'step_id'])['duration'].agg(['sum', 'count']).reset_index()\n",
    "stu_prob_stats = step_stats.groupby('stu_id')['count'].describe()\n",
    "stu_prob_stats.columns = [\"Step Attempt %s\" % col for col in stu_prob_stats.columns]\n",
    "d = step_stats.groupby('stu_id')['sum'].describe()\n",
    "d.columns = [\"Step Duration %s\" % col for col in d.columns]\n",
    "stu_prob_stats = pd.concat([stu_prob_stats, d], axis=1)\n",
    "stu_prob_stats.head()\n",
    "\n",
    "# kc_stats = tx[['stu_id', 'kc', 'step_id']].drop_duplicates().groupby(['stu_id', 'kc']).count()\n",
    "stu_kc_stats = tx[['stu_id', 'kc', 'step_id']].drop_duplicates().groupby(['stu_id', 'kc']).count().reset_index()\n",
    "stu_kc_stats.rename(columns={'step_id': 'kc opportunities'}, inplace=True)\n",
    "kc_stats = stu_kc_stats.groupby('kc').describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of transactions with negative duration\n",
    "# This is a sanity check\n",
    "count = np.sum(tx['duration'] < 0)\n",
    "logger.info(\"Number of transactions with negative duration: %i out of %i(%.2f%%)\" % (count, tx.shape[0], count * 100 / tx.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 10\n",
    "num_rows = 3\n",
    "num_cols = 6\n",
    "row_height = 3\n",
    "col_width = 3\n",
    "plt.figure(figsize=(col_width*num_cols, row_height*num_rows+num_rows))\n",
    "\n",
    "row = 0\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 1)\n",
    "plt.hist(stu_prob_stats['Step Attempt mean'], bins=num_bins)\n",
    "plt.title(\"Mean Attempts per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 2)\n",
    "plt.hist(stu_prob_stats['Step Attempt std'], bins=num_bins)\n",
    "plt.title(\"Standard Dev Attempts per step\")\n",
    "\n",
    "\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 3)\n",
    "plt.hist(stu_prob_stats['Step Attempt 25%'], bins=num_bins)\n",
    "plt.title(\"Q1 Attempts per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 4)\n",
    "plt.hist(stu_prob_stats['Step Attempt 50%'], bins=num_bins)\n",
    "plt.title(\"Q2 Attempts per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 5)\n",
    "plt.hist(stu_prob_stats['Step Attempt 75%'], bins=num_bins)\n",
    "plt.title(\"Q3 Attempts per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 6)\n",
    "plt.hist(stu_prob_stats['Step Attempt max'], bins=num_bins)\n",
    "plt.title(\"Max Attempts per step\")\n",
    "\n",
    "row = 1\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 1)\n",
    "plt.hist(stu_prob_stats['Step Duration mean'], bins=num_bins)\n",
    "plt.title(\"Mean Time per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 2)\n",
    "plt.hist(stu_prob_stats['Step Duration std'], bins=num_bins)\n",
    "plt.title(\"Standard Dev Time per step\")\n",
    "\n",
    "\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 3)\n",
    "plt.hist(stu_prob_stats['Step Duration 25%'], bins=num_bins)\n",
    "plt.title(\"Q1 Time per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 4)\n",
    "plt.hist(stu_prob_stats['Step Duration 50%'], bins=num_bins)\n",
    "plt.title(\"Q2 Time per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 5)\n",
    "plt.hist(stu_prob_stats['Step Duration 75%'], bins=num_bins)\n",
    "plt.title(\"Q3 Time per step\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 6)\n",
    "plt.hist(stu_prob_stats['Step Duration max'], bins=num_bins)\n",
    "plt.title(\"Max Time per step\")\n",
    "\n",
    "row = 2\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 1)\n",
    "plt.hist(kc_stats[('kc opportunities', 'mean')], bins=num_bins)\n",
    "plt.title(\"Mean opportunities per kc\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 2)\n",
    "plt.hist(kc_stats[('kc opportunities', 'std')], bins=num_bins)\n",
    "plt.title(\"Standard Dev opportunities per kc\")\n",
    "\n",
    "\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 3)\n",
    "plt.hist(kc_stats[('kc opportunities', '25%')], bins=num_bins)\n",
    "plt.title(\"Q1 opportunities per kc\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 4)\n",
    "plt.hist(kc_stats[('kc opportunities', '50%')], bins=num_bins)\n",
    "plt.title(\"Q2 opportunities per kc\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 5)\n",
    "plt.hist(kc_stats[('kc opportunities', '75%')], bins=num_bins)\n",
    "plt.title(\"Q3 opportunities per kc\")\n",
    "plt.subplot(num_rows,num_cols,num_cols*row + 6)\n",
    "plt.hist(kc_stats[('kc opportunities', 'max')], bins=num_bins)\n",
    "plt.title(\"Max opportunities per kc\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-simulation run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Run Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims=1\n",
    "stu_per_sim = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simualtion Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_curriculum(domain,\n",
    "                   num_units=1,\n",
    "                   mean_sections=4,\n",
    "                   stdev_sections=2,\n",
    "                   mean_unit_kcs=22,\n",
    "                   stdev_unit_kcs=23,\n",
    "                   section_kcs_lambda=6,\n",
    "                   mean_steps=10,\n",
    "                   stdev_steps=4,\n",
    "                   mean_prob_kcs=6,\n",
    "                   stdev_prob_kcs=3,\n",
    "                   num_practice=100,\n",
    "                   \n",
    "                  ):# Generating the Curriculum and domain together\n",
    "#    domain = Domain()\n",
    "    curric = CogTutorCurriculum(domain)\n",
    "    curric.generate(num_units=num_units,\n",
    "                   mean_sections=mean_sections,\n",
    "                   stdev_sections=stdev_sections,\n",
    "                   mean_unit_kcs=mean_unit_kcs,\n",
    "                   stdev_unit_kcs=stdev_unit_kcs,\n",
    "                   section_kcs_lambda=section_kcs_lambda,\n",
    "                   mean_steps=mean_steps,\n",
    "                   stdev_steps=stdev_steps,\n",
    "                   mean_prob_kcs=mean_prob_kcs,\n",
    "                   stdev_prob_kcs=stdev_prob_kcs,\n",
    "                   num_practice=num_practice\n",
    "                   )\n",
    "    \n",
    "    # Insert domain to db\n",
    "    #db.domains.insert_one(domain.to_dict())\n",
    "    #db.kcs.insert_many([kc.__dict__ for kc in domain.kcs])\n",
    "\n",
    "    # Insert Curriculum to db\n",
    "    #curric_util = DB_Curriculum_Mapper(db_params)\n",
    "    #curric_util.write_to_db(curric)\n",
    "    \n",
    "    return curric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_students(domain, num_students=2):\n",
    "    students = [DomainTuner(domain) for i in range(num_students)]\n",
    "    logger.info(\"Sample student:\\n%s\" % str(students[0]))\n",
    "    logger.info(\"Inserting %i students to db\" % len(students))\n",
    "    result = db.students.insert_many([stu.to_dict() for stu in students])\n",
    "    logger.info(\"Db insert success: %s\" % result.acknowledged)\n",
    "    return students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_students(domain, curric, students):    \n",
    "    for i, stu in enumerate(students):\n",
    "        logger.info(\"Simulating student #%i\" % i)\n",
    "        sim = SelfEffSimulation(domain, curric, stu)\n",
    "        sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim_stats(curric, students):\n",
    "\n",
    "    stu_ids = [stu._id for stu in students]\n",
    "    tx = pd.DataFrame(db.tutor_events.find({'type': \"Tutor Input\", 'stu_id': {\"$in\": stu_ids}}))\n",
    "    logger.info(\"Learner Transactions: %s\" % str(tx.shape))\n",
    "    # Add kc field that reduces list of kcs to 1 kc\n",
    "    tx['kc'] = tx.apply(lambda x: x['kcs'][0]['_id'], axis=1)\n",
    "    \n",
    "    # Aggregate Learner transaction stats\n",
    "\n",
    "    # Total Transaction counts\n",
    "    stu_stats = tx.groupby('stu_id').agg({'_id': 'count', \n",
    "                                          'duration': np.sum,\n",
    "                                         })\n",
    "    stu_stats.rename(columns={'_id': \"Total Tx\",\n",
    "                              'duration': 'Total Time'}, \n",
    "                             inplace = True)\n",
    "    stu_stats['Total Time(hours)'] = stu_stats['Total Time'].apply(lambda x: x / 3600)\n",
    "    #logger.info(\"Number of students: %i\" % stu_stats.shape[0])\n",
    "    #logger.info(stu_stats[\"Total Tx\"].describe())\n",
    "\n",
    "    # Total of each outcome\n",
    "    d = tx.groupby(['stu_id','outcome'])['_id'].count().reset_index().pivot(index='stu_id', columns='outcome', values='_id')\n",
    "    # Proporation of each outcome\n",
    "    if len(d.columns) > 1:\n",
    "        d['Total'] = d.sum(axis=1)\n",
    "    else:\n",
    "        d['Total'] = d.iloc[:,0]\n",
    "\n",
    "    for col in d.columns:\n",
    "        if col != 'Total':\n",
    "            d['Pct %s' % col] = d[col] / d['Total']\n",
    "    stu_stats = pd.concat([stu_stats, d], axis=1)\n",
    "    \n",
    "    # Calculate attempts per ste\n",
    "    stu_step_stats = tx.groupby(['stu_id', 'step_id'])['_id'].count().reset_index()\n",
    "    stu_step_stats.rename(columns={'_id': 'step attempts'}, inplace=True)\n",
    "    step_stats = stu_step_stats.groupby('stu_id').describe()\n",
    "    \n",
    "    # Calculate opportunities per kc per student\n",
    "    stu_kc_stats = tx[['stu_id', 'kc', 'step_id']].drop_duplicates().groupby(['stu_id', 'kc']).count().reset_index()\n",
    "    stu_kc_stats.rename(columns={'step_id': 'kc opportunities'}, inplace=True)\n",
    "    kc_stats = stu_kc_stats.groupby('kc').describe()\n",
    "\n",
    "    \n",
    "    # consolidate distributional stats of resulting data\n",
    "\n",
    "    stats = {}\n",
    "    stats['Step attempts mean'] = step_stats[('step attempts', 'mean')].mean()\n",
    "    stats['Step attempts std'] = step_stats[('step attempts', 'std')].mean()\n",
    "    accuracy_dist = stu_stats['Pct Correct'].describe()\n",
    "    stats['Mean Pct Correct'] = accuracy_dist['mean']\n",
    "    stats['Std Pct Correct'] = accuracy_dist['std']\n",
    "    stats['KC opportunity mean'] = kc_stats[('kc opportunities', 'mean')].mean()\n",
    "    stats['KC opportunity std'] = kc_stats[('kc opportunities', 'std')].mean()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(num_stu, hyperparams=None):\n",
    "    domain = Domain()\n",
    "    # Set domain hyperparams\n",
    "    if hyperparams is not None:\n",
    "        domain.set_kc_hyperparams(**hyperparams)\n",
    "    logger.info(\"*** domain has %i kcs before curric *****\" % len(domain.kcs) )\n",
    "    curric = gen_curriculum(domain)\n",
    "    logger.info(\"*** domain has %i kcs *****\" % len(domain.kcs) )\n",
    "    students = gen_students(domain, num_stu)\n",
    "    simulate_students(domain, curric, students)\n",
    "    stats = calc_sim_stats(curric, students)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning on distribution of opportunities per kc, attempts per step, and student accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {\n",
    "    'Step attempts mean': 1,\n",
    "    'Step attempts std': 0.4,\n",
    "    'Mean Pct Correct': 0.8,\n",
    "    'Std Pct Correct': 0.1,\n",
    "    'KC opportunity mean': 7,\n",
    "    'KC opportunity std': 3\n",
    "}\n",
    "\n",
    "def target_obj(pred, target=target):\n",
    "    d = pd.DataFrame([pred, target])\n",
    "    err = math.sqrt(np.sum(d.apply(lambda x: (x[1] - x[0])**2, axis=0)))\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_sim_params(params):\n",
    "    start = dt.now()\n",
    "    logger.error(\"running eval sim with params: %s\" % str(params))\n",
    "    db_util = mongo.Data_Utility(data_path, db_params)\n",
    "    param_dict = {\n",
    "            'm_l0': params[0],\n",
    "            'sd_l0':params[1],\n",
    "            'm_t':params[2],\n",
    "            'sd_t':params[3],\n",
    "            'm_s':params[4],\n",
    "            'sd_s':params[5],\n",
    "            'm_g':params[6],\n",
    "            'sd_g':params[7]\n",
    "    }\n",
    "    result = run_sim(stu_per_sim, param_dict)\n",
    "    err = target_obj(result)\n",
    "    #param_dict['error'] = err\n",
    "    db_util.clear_db()\n",
    "    end = dt.now()\n",
    "    logger.error(\"Run took %f seconds with err: %f\" % ((end - start).total_seconds(), err))\n",
    "\n",
    "    return err\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tuning simulation runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'm_l0':0.5,\n",
    "            'sd_l0':0.1,\n",
    "            'm_t':0.2,\n",
    "            'sd_t':0.03,\n",
    "            'm_s':0.05,\n",
    "            'sd_s':0.03,\n",
    "            'm_g':0.8,\n",
    "            'sd_g':0.15\n",
    "}\n",
    "bounds = Bounds([0.2, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "               [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n",
      "ERROR:main:Run took 2.427222 seconds with err: 4.738486\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 2.427948 seconds with error: 4.738486061149542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 1.328470 seconds with err: 5.007400\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 1.329420 seconds with error: 5.007399791028455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 0.503259 seconds with err: 4.279190\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 0.504121 seconds with error: 4.279190299691734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 7.563066 seconds with err: 4.793745\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 7.563976 seconds with error: 4.793744508406469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 0.846466 seconds with err: 5.298943\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 0.847508 seconds with error: 5.298942962553504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 1.683086 seconds with err: 4.720333\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 1.684128 seconds with error: 4.720332646362833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 3.326609 seconds with err: 4.926075\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 3.327884 seconds with error: 4.926074932447027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 3.601414 seconds with err: 4.956323\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 3.602619 seconds with error: 4.9563231325482535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 3.845001 seconds with err: 4.674420\n",
      "ERROR:main:running eval sim with params: [0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 3.846141 seconds with error: 4.674420368818954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 1.305132 seconds with err: 5.009962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run took 1.306344 seconds with error: 5.0099622001823025\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Test specific case\n",
    "params = [0.7,  0.3,  0.8,  0.05, 0.3,  0.1,  1.0,  0.01]\n",
    "for i in range(10):\n",
    "    start = dt.now()\n",
    "    result = eval_sim_params(params)\n",
    "    end = dt.now()\n",
    "    time = (end - start).total_seconds()\n",
    "    print(\"Run took %f seconds with error: %s\" % (time, str(result)))\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:running eval sim with params: [0.36842612356718385, 0.29936150760697633, 0.5951070668934576, 0.03861543021878237, 0.12028078303276414, 0.041963664561354246, 0.9622517234660605, 0.1705944577475439]\n",
      "ERROR:main:Run took 5.813775 seconds with err: 3.260485\n",
      "ERROR:main:running eval sim with params: [0.624031662102451, 0.08593886526163075, 0.29136664714666105, 0.025390797838511864, 0.25185944051570847, 0.01817187183482455, 0.2014876047795596, 0.09389067099342573]\n",
      "ERROR:main:Run took 34.294522 seconds with err: 37.544152\n",
      "ERROR:main:running eval sim with params: [0.2242041376949802, 0.023903622404786766, 0.48477967316262055, 0.025363664227659143, 0.09605737159496047, 0.09893797617032976, 0.6789484202496915, 0.17036237225959022]\n",
      "ERROR:main:Run took 4.561430 seconds with err: 2.319149\n",
      "ERROR:main:running eval sim with params: [0.37026082350345235, 0.029419436557063423, 0.2922539663534928, 0.028682357067283747, 0.19797635059640764, 0.09631065902325427, 0.7318978404029074, 0.1503874626727287]\n",
      "ERROR:main:Run took 4.917623 seconds with err: 1.693223\n",
      "ERROR:main:running eval sim with params: [0.26696299290852904, 0.26955823834939224, 0.3552006567437914, 0.03522351142957899, 0.08497807771047816, 0.031860296241575714, 0.9219635217600324, 0.04061498486757077]\n",
      "ERROR:main:Run took 4.986927 seconds with err: 1.071184\n",
      "ERROR:main:running eval sim with params: [0.6484571247084121, 0.07155593561729887, 0.12824240797703482, 0.02990385558189404, 0.2413954191852966, 0.04533229942312218, 0.8030129342446012, 0.1521678012239822]\n",
      "ERROR:main:Run took 24.853557 seconds with err: 8.651165\n",
      "ERROR:main:running eval sim with params: [0.501101813501509, 0.18443429356811958, 0.39453493950019175, 0.026474791453978498, 0.27994309099975256, 0.07776519982629203, 0.26730351373575395, 0.09082787436951938]\n",
      "ERROR:main:Run took 1.209895 seconds with err: 2.301214\n",
      "ERROR:main:running eval sim with params: [0.5498873442949299, 0.08227019507772174, 0.16619464141769982, 0.04472414664520457, 0.25561970047251853, 0.07151423293606805, 0.6075878430360279, 0.07640003414073784]\n",
      "ERROR:main:Run took 11.645748 seconds with err: 5.941411\n",
      "ERROR:main:running eval sim with params: [0.35884222959294443, 0.09643492441105889, 0.6685275768223649, 0.022227143795189565, 0.18057749302012352, 0.08682396140980982, 0.24814405813345583, 0.16302466989757933]\n",
      "ERROR:main:Run took 5.656395 seconds with err: 3.617852\n",
      "ERROR:main:running eval sim with params: [0.6867819341970007, 0.2182613880815744, 0.32978810125255753, 0.0337397127917698, 0.13647488818025258, 0.0377564420403445, 0.6815714679927329, 0.14714254904977356]\n",
      "ERROR:main:Run took 3.539459 seconds with err: 1.812942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average run time: 10.149077 seconds\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0.2,0.7), (0.01,0.3), (0.01,0.8), (0.01,0.05),\n",
    "        (0.01,0.3), (0.01,0.1), (0.01,1.0),(0.01,0.2)]\n",
    "times = []\n",
    "for i in range(10):\n",
    "    params = [\n",
    "        random.uniform(bounds[0][0], bounds[0][1]),\n",
    "        random.uniform(bounds[1][0], bounds[1][1]),\n",
    "        random.uniform(bounds[2][0], bounds[2][1]),\n",
    "        random.uniform(bounds[3][0], bounds[3][1]),\n",
    "        random.uniform(bounds[4][0], bounds[4][1]),\n",
    "        random.uniform(bounds[5][0], bounds[5][1]),\n",
    "        random.uniform(bounds[6][0], bounds[6][1]),\n",
    "        random.uniform(bounds[7][0], bounds[7][1])\n",
    "    ]\n",
    "    start = dt.now()\n",
    "    result = eval_sim_params(params)\n",
    "    end = dt.now()\n",
    "    times.append((end - start).total_seconds())\n",
    "    #print(\"Run took %f seconds\" % times[-1])\n",
    "    #print(result)\n",
    "print(\"average run time: %f seconds\" % np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = list(params.values())\n",
    "print(\"Initial parameters: %s\" % str(init_params))\n",
    "print(\"Bounds: %s\" % str(bounds))\n",
    "start = dt.now()\n",
    "# Commented out for now\n",
    "#min_result = minimize(eval_sim_params, init_params, \n",
    "#                      method='powell', bounds=bounds)\n",
    "print(\"operation took: %s\" % str((end - start)))\n",
    "print(\"Minimize result: %s\" % str(min_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:running eval sim with params: [0.2  0.01 0.1  0.01 0.01 0.01 0.2  0.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds: [(0.2, 0.7), (0.01, 0.3), (0.1, 0.8), (0.01, 0.05), (0.01, 0.3), (0.01, 0.1), (0.2, 1.0), (0.01, 0.2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:main:Run took 49.048742 seconds with err: 12.989448\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 1.856696 seconds with err: 4.966432\n",
      "ERROR:main:running eval sim with params: [0.7  0.01 0.1  0.01 0.01 0.01 0.2  0.01]\n",
      "ERROR:main:Run took 23.094488 seconds with err: 4.660914\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.01 0.01 0.01 0.2  0.01]\n",
      "ERROR:main:Run took 9.365216 seconds with err: 12.729856\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.01 0.2  0.01]\n",
      "ERROR:main:Run took 3.297495 seconds with err: 4.799626\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.01 0.2  0.01]\n",
      "ERROR:main:Run took 2.673046 seconds with err: 4.257984\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.01 0.2  0.01]\n",
      "ERROR:main:Run took 4.108311 seconds with err: 5.051044\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.1  0.2  0.01]\n",
      "ERROR:main:Run took 4.705067 seconds with err: 4.827364\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.1  1.   0.01]\n",
      "ERROR:main:Run took 2.949998 seconds with err: 4.932358\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.1  0.2  0.2 ]\n",
      "ERROR:main:Run took 1.607507 seconds with err: 5.216861\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.01 1.   0.01]\n",
      "ERROR:main:Run took 1.737783 seconds with err: 5.221161\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.01 1.   0.2 ]\n",
      "ERROR:main:Run took 2.517299 seconds with err: 4.801292\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.3  0.01 0.2  0.2 ]\n",
      "ERROR:main:Run took 3.623004 seconds with err: 7.308906\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.1  0.2  0.01]\n",
      "ERROR:main:Run took 4.844781 seconds with err: 4.624928\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.1  1.   0.01]\n",
      "ERROR:main:Run took 2.484416 seconds with err: 4.825174\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 1.137963 seconds with err: 4.975588\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.1  0.2  0.2 ]\n",
      "ERROR:main:Run took 3.195035 seconds with err: 5.315645\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.01 1.   0.01]\n",
      "ERROR:main:Run took 1.815976 seconds with err: 5.223780\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.01 1.   0.2 ]\n",
      "ERROR:main:Run took 0.973230 seconds with err: 5.076483\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.05 0.01 0.01 0.2  0.2 ]\n",
      "ERROR:main:Run took 3.136846 seconds with err: 4.727408\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.01 0.2  0.01]\n",
      "ERROR:main:Run took 6.118694 seconds with err: 4.793947\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.1  0.2  0.01]\n",
      "ERROR:main:Run took 11.017636 seconds with err: 4.910876\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.1  1.   0.01]\n",
      "ERROR:main:Run took 1.648078 seconds with err: 5.319960\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 0.475005 seconds with err: 4.620506\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.1  0.2  0.2 ]\n",
      "ERROR:main:Run took 5.205012 seconds with err: 8.341646\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.01 1.   0.01]\n",
      "ERROR:main:Run took 3.145765 seconds with err: 5.038303\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.01 1.   0.2 ]\n",
      "ERROR:main:Run took 1.836821 seconds with err: 4.889435\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.3  0.01 0.2  0.2 ]\n",
      "ERROR:main:Run took 5.709848 seconds with err: 9.483796\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.1  0.2  0.01]\n",
      "ERROR:main:Run took 3.987270 seconds with err: 5.045669\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.1  1.   0.01]\n",
      "ERROR:main:Run took 0.577720 seconds with err: 4.921495\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 4.501340 seconds with err: 5.073451\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.1  0.2  0.2 ]\n",
      "ERROR:main:Run took 9.311336 seconds with err: 11.260475\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.01 1.   0.01]\n",
      "ERROR:main:Run took 4.175007 seconds with err: 4.960131\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.01 1.   0.2 ]\n",
      "ERROR:main:Run took 1.631568 seconds with err: 5.157177\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.8  0.01 0.01 0.01 0.2  0.2 ]\n",
      "ERROR:main:Run took 8.192262 seconds with err: 11.172085\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.01 0.01 0.2  0.01]\n",
      "ERROR:main:Run took 3.582406 seconds with err: 4.508010\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.01 0.2  0.01]\n",
      "ERROR:main:Run took 79.140139 seconds with err: 13.920974\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.1  0.2  0.01]\n",
      "ERROR:main:Run took 12.495530 seconds with err: 17.162735\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.1  1.   0.01]\n",
      "ERROR:main:Run took 6.052818 seconds with err: 11.684256\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 12.013937 seconds with err: 9.769164\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.1  0.2  0.2 ]\n",
      "ERROR:main:Run took 87.507513 seconds with err: 33.384172\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.01 1.   0.01]\n",
      "ERROR:main:Run took 19.572106 seconds with err: 9.242038\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.01 1.   0.2 ]\n",
      "ERROR:main:Run took 30.970664 seconds with err: 25.080326\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.3  0.01 0.2  0.2 ]\n",
      "ERROR:main:Run took 80.989614 seconds with err: 20.203747\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.01 0.1  0.2  0.01]\n",
      "ERROR:main:Run took 76.108224 seconds with err: 18.829480\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.01 0.1  1.   0.01]\n",
      "ERROR:main:Run took 11.049195 seconds with err: 15.338175\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.01 0.1  1.   0.2 ]\n",
      "ERROR:main:Run took 8.343876 seconds with err: 9.710673\n",
      "ERROR:main:running eval sim with params: [0.7  0.3  0.1  0.05 0.01 0.1  0.2  0.2 ]\n"
     ]
    }
   ],
   "source": [
    "#bounds = [(0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0),\n",
    "#          (0.7, 0.3, 0.8, 0.05, 0.3, 0.1, 1.0, 0.2)]\n",
    "bounds = [(0.2,0.7), (0.01,0.3), (0.1,0.8), (0.01,0.05),\n",
    "        (0.01,0.3), (0.01,0.1), (0.2,1.0),(0.01,0.2)]\n",
    "#init_params = list(params.values())\n",
    "#print(\"Initial parameters: %s\" % str(init_params))\n",
    "print(\"Bounds: %s\" % str(bounds))\n",
    "start = dt.now()\n",
    "min_result = optimize.shgo(eval_sim_params, bounds)\n",
    "end = dt.now()\n",
    "print(\"operation took: %s\" % str((end - start)))\n",
    "print(\"Minimize result: %s\" % str(min_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of Simulation Runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
